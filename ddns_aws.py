import os
import json
import requests
import time
from datetime import datetime
import logging
from logging.handlers import RotatingFileHandler
from sys import exit


# path = os.path.dirname(os.path.abspath(__file__)) + "/"
path = "./"


def get_time():
	now = datetime.now()
	current_time = now.strftime("%Y-%m-%d-%H:%M:%S")
	return current_time;

def force_create_dir ( name ):
	if not os.path.exists(path+name):
		os.makedirs(path+name)
		print (name, "/ created")

# Scan all hostzones and locate target (old) IP values, generate request json file to change the target IP record value
def generate_update_req ( host_zone_ids, old_ip, new_ip ):
	logging.info (f"Start to generate aws request json for {old_ip} => {new_ip}")
	
	# Search each hostzone for ip's that matches
	for host_zone_id in host_zone_ids:
		logging.debug (f"Scanning hostzone {host_zone_id}")
		
		get_tries = 0;
		while get_tries < 4:
			# GET existing hostzone record sets
			temp_file_location = path + "temps/" + host_zone_id +"_get.json"
			exit_code = os.system ("aws route53 list-resource-record-sets --hosted-zone-id " + host_zone_id + " > " + temp_file_location )
			if (exit_code == 0):
				logging.info (f"Query for hostzone {host_zone_id} succeed with tries: {get_tries}")
				break;
			else:
				get_tries += 1;
				logging.error (f"Query for hostzone {host_zone_id} failed with tries: {get_tries}, sleep {get_tries*30} min for next try")
				time.sleep ( get_tries * 30)

		if (get_tries == 4):
			logging.critical (f"Query for hostzone {host_zone_id} failed with tries: {get_tries}, exit()")
			exit();

		# load queried data
		f = open (temp_file_location)
		data = json.load(f);
		f.close();
		logging.debug (f"GOT record sets: {data}")

		os.system ("rm " + temp_file_location)
		logging.info("Removed temp GET file")


		logging.info ("Generates the change request json")
		
		# The final request json file
		change_target_count = 0 
		out_jason = {
			"Comment": "",
			"Changes": []
		}

		set_len = len(data["ResourceRecordSets"]);
		logging.debug (f"Retrieved record sets has { set_len } items " )
		# Scan each record sets
		for i in range ( set_len ):
			record_set = data["ResourceRecordSets"][i];
			logging.debug ( f"Scanning {i}: {record_set}" )

			# Scan each record ( may have multiple values(ips) )
			for j in range ( len (record_set["ResourceRecords"])):
				record = record_set["ResourceRecords"][j]
				logging.debug ( f"{record}" )
				if ( record["Value"] == old_ip ):
					logging.debug (f"found match with {record} and target ip (old ip) {old_ip}")
					change_target_count += 1

					logging.info ("Append changing elements to final changing request")
					record["Value"] = new_ip
					change_request = {
						"Action": "UPSERT"
					}
					change_request["ResourceRecordSet"] = data["ResourceRecordSets"][i]
					out_jason["Changes"].append( change_request )

					logging.debug (f"after appending, out_jason is: {out_jason}")

		logging.debug ( f"Target record counts: {change_target_count}")
		# if no target found in the search hostzone, treat as miss configuration
		if (change_target_count == 0):
			logging.critical (f"No target ip (old): {old_ip} found in the given Hostzones. Exit.")
			exit()

		logging.info (f"Generate final request json file for hostzone {host_zone_id}")
		with open ( path + "temps/" + host_zone_id + '_change_req.json', 'w') as json_file:
			json.dump (out_jason, json_file)


# Send aws UPSERT request based on files generated by generate_update_req()
# Possible feature improve: tacking request status after request sucess until the request is actually applied (INSYNC), resend if it fails
def send_request ( host_zone_ids ):
	logging.info (f"Start to send aws request")
	for host_zone_id in host_zone_ids:
		logging.debug (f"Requesting for hostzone {host_zone_id}")

		get_tries = 0;
		while get_tries < 4:
			exit_code = os.system ("aws route53 change-resource-record-sets --hosted-zone-id " + host_zone_id + " --change-batch file://" + path + "temps/" + host_zone_id +"_change_req.json")
			if (exit_code == 0):
				logging.info (f"Request for hostzone {host_zone_id} succeed with tries: {get_tries}")
				break;
			else:
				get_tries += 1;
				logging.error (f"Request for hostzone {host_zone_id} failed with tries: {get_tries}, sleep {get_tries*30} min for next try")
				time.sleep ( get_tries * 30)

		if (get_tries == 4):
			logging.critical (f"Request for hostzone {host_zone_id} failed with tries: {get_tries}, exit()")
			exit();

		# get response change status ID
		# check status ID until its INSYNC

		os.system ("rm " + path + "temps/" + host_zone_id + '_change_req.json')
		logging.info("Removed temp change_req file")




force_create_dir ('logs')
force_create_dir ('temps')

logging.basicConfig ( 
	handlers=[
		RotatingFileHandler(path+"logs/test.log", maxBytes=100000, backupCount=2),
		logging.StreamHandler()
	],
	format='%(asctime)s [%(levelname)s]:\t%(message)s', 
	datefmt='%H:%M:%S %d-%b-%y', 
	level=logging.INFO
)


logging.info ("=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=")
logging.info("Initialize...")
logging.info("Load config files")


# Read configuration file
f = open (path + "ddns_aws.config")
configs = json.load(f);
f.close();

# Log loaded configs
host_zone_ids = configs["HostZoneIDs"];
logging.debug ("Hostzones loaded: {}".format(', '.join ( map(str, host_zone_ids) ) ) ) ;

current_ip = configs["CurrentIP"];
logging.debug ( f"Current IP loaded: {current_ip} "  )

interval = int (configs["IPCheckInterval"])
logging.debug ( f"IP check interval loaded: {interval} min" )

# Test if server and hostzones can be reached
for ids in host_zone_ids:
	exit_code = os.system ("aws route53 list-resource-record-sets --hosted-zone-id " + ids + " > " + path + "test_hostzone.temp");
	if ( exit_code != 0 ):
		logging.critical ( f"Hostzone {ids} test failed: Cannot retrieve data from server")
		os.system ("rm " + path + "test_hostzone.temp")
		logging.info("removed test temp file")
		exit()
	logging.info ( f"Hostzone {ids} test proceeds ok")
logging.info ( "All hostzone test passed. ")
os.system ("rm " + path + "test_hostzone.temp")
logging.info("removed test temp file")
logging.info ("=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=x=")


while True:
	logging.info ("===============================================================")
	logging.info ("DDNS iteration service starts...")
	ip = '0.0.0.0'
	ip_get_res_code = 404;
	ip_tries = 0;

	logging.debug (f"before query: current_ip: {current_ip}, ip_get: {ip}, ip_get_res_code: {ip_get_res_code}, # of tries: {ip_tries}")

	while ( ip_tries < 10 ):
		ip_res = requests.get ('https://checkip.amazonaws.com');
		ip_get_res_code = ip_res.status_code;
		ip_tries = ip_tries + 1
		if ( ip_get_res_code == 200 ):
			ip = ip_res.text.strip();
			logging.debug (f"after query: current_ip: {current_ip}, ip_get: {ip}, ip_get_res_code: {ip_get_res_code}, # of tries: {ip_tries}")
			break;

		logging.debug (f"after query: ip_get_res_code: {ip_get_res_code}, # of tries: {ip_tries}")
		logging.error (f"GET public ip failed with {ip_tries} tries, sleep { pow(2, ip_tries) * 60 } min for next try")
		time.sleep ( pow (2, ip_tries) * 60)
	
	# if failed
	if ( ip_tries == 10 ):
		logging.critical (f"Cannot get IP address for too long: tries: {ip_tries}. exit()")
		exit();

	# if success
	logging.info (f"Retrived ip: {ip}")

	# Check if there is IP change
	if ( ip != current_ip ):
		logging.info (f"IP change detected, current_ip: {current_ip}, new retrieved ip: {ip}.")

		flag = generate_update_req ( host_zone_ids, current_ip, ip);

		logging.info ("Scan for all hostzones completed. Initiate change requests")
		send_request ( host_zone_ids );
		logging.info ("Requests for all hostzones completed. Now update config file")
		current_ip = ip;


		# Update configuration file
		f = open (path + "ddns_aws.config")
		configs = json.load(f);
		configs["CurrentIP"] = ip
		f.close();
		with open (path + "ddns_aws.config", 'w') as json_file:
			json.dump (configs, json_file)


	logging.info (f"Completed! Now wait for the next check in {interval} min")
	time.sleep( interval*60 )


